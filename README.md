# ğŸ“˜ Supervised Learning (Part I of the Repository)

## ğŸ§  What is Supervised Learning?

Supervised Learning is one of the most fundamental approaches in machine learning. In this paradigm, we train models using **labeled datasets**, where each example consists of an input and a known output (label). The objective is to learn a function that maps inputs to outputs and generalizes well to unseen data.

This section is the **first chapter of the repository** and provides a thorough exploration of supervised learning models, grouped by algorithmic family. It covers both theoretical and practical aspects of each model, along with Python notebooks and usage examples.

---

## ğŸ“ docs/01_Supervised_Learning/

â”œâ”€â”€ [Introduction.md](docs/01_Supervised_Learning/Introduction.md)  
â€ƒâ€ƒğŸ“˜ *Introduction to Supervised Learning*

---

### ğŸ“‚ 01_Regression/
- [01_Linear_Regression.md](docs/01_Supervised_Learning/01_Regression/01_Linear_Regression.md) â€“ Linear Regression  
- [02_Polynomial_Regression.md](docs/01_Supervised_Learning/01_Regression/02_Polynomial_Regression.md) â€“ Polynomial Regression  
- [03_Logistic_Regression.md](docs/01_Supervised_Learning/01_Regression/03_Logistic_Regression.md) â€“ Logistic Regression  

---

### ğŸ“‚ 02_Tree_Based_Models/
- [01_Decision_Trees.md](docs/01_Supervised_Learning/02_Tree_Based_Models/01_Decision_Trees.md) â€“ Decision Trees  
- [02_Random_Forest.md](docs/01_Supervised_Learning/02_Tree_Based_Models/02_Random_Forest.md) â€“ Random Forest  
- [03_Gradient_Boosting.md](docs/01_Supervised_Learning/02_Tree_Based_Models/03_Gradient_Boosting.md) â€“ Gradient Boosting  

---

### ğŸ“‚ 03_Probability_Based_Models/
- [01_Naive_Bayes.md](docs/01_Supervised_Learning/03_Probability_Based_Models/01_Naive_Bayes.md) â€“ Naive Bayes  
- [02_LDA.md](docs/01_Supervised_Learning/03_Probability_Based_Models/02_LDA.md) â€“ Linear Discriminant Analysis (LDA)  

---

### ğŸ“‚ 04_Distance_Based_Models/
- [01_KNN.md](docs/01_Supervised_Learning/04_Distance_Based_Models/01_KNN.md) â€“ k-Nearest Neighbors  
- [02_SVM.md](docs/01_Supervised_Learning/04_Distance_Based_Models/02_SVM.md) â€“ Support Vector Machines  

---

### ğŸ“‚ 05_Neural_Networks/
- [01_Perceptron.md](docs/01_Supervised_Learning/05_Neural_Networks/01_Perceptron.md) â€“ Simple Perceptron  
- [02_ML.md](docs/01_Supervised_Learning/05_Neural_Networks/02_ML.md) â€“ Multilayer Perceptron (MLP)  

---

### ğŸ“‚ 06_Model_Evaluation/
- [01_Evaluation_Metrics.md](docs/01_Supervised_Learning/06_Model_Evaluation/01_Evaluation_Metrics.md) â€“ Evaluation Metrics  
- [02_Cross_Validation.md](docs/01_Supervised_Learning/06_Model_Evaluation/02_Cross_Validation.md) â€“ Cross-Validation  
- [03_Regularization.md](docs/01_Supervised_Learning/06_Model_Evaluation/03_Regularization.md) â€“ Regularization  
- [04_Hyperparameter_Tuning.md](docs/01_Supervised_Learning/06_Model_Evaluation/04_Hyperparameter_Tuning.md) â€“ Hyperparameter Tuning  



---


## âœ… Closing This Chapter

This concludes the **Supervised Learning** section of the repository.

You now have a solid foundation on:
- The most important classical ML models
- How to evaluate and improve them
- When and why to use each approach

ğŸ‘‰ Next up: **Unsupervised Learning** â€” where no labels are required, and structure must be discovered from raw data.
