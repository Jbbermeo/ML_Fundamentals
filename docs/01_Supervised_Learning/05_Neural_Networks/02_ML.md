# üìò Multilayer Perceptron (MLP)

## üìå Introduction
A **Multilayer Perceptron (MLP)** is a type of **feedforward artificial neural network** that consists of at least **three layers of nodes**:
1. **Input Layer**
2. **Hidden Layer(s)**
3. **Output Layer**

Unlike the simple perceptron, which can only learn linear decision boundaries, the MLP can learn **non-linear functions** through the use of **non-linear activation functions** and **multiple layers**.

MLPs are the foundation of modern deep learning systems and are commonly used for tasks like classification, regression, and function approximation.

---

## üß† Architecture
### üîπ Layers and Neurons
Each neuron in an MLP computes a weighted sum of its inputs and passes the result through a **non-linear activation function**:

 $z = \mathbf{w}^T \mathbf{x} + b$

 $a = \phi(z)$

Where:
- $( \mathbf{x} )$: input vector
- $( \mathbf{w} )$: weight vector
- $( b )$: bias
- $( \phi )$: activation function (e.g., ReLU, sigmoid, tanh)

### üîπ Fully Connected
- Every neuron in a layer is connected to **every neuron** in the next layer.
- These connections have **trainable weights** that are learned from the data.

---

## ‚öôÔ∏è Activation Functions
Non-linear activation functions allow the network to learn complex patterns:
| Activation | Formula | Properties |
|------------|---------|------------|
| ReLU       | $ \max(0, x)  $| Fast, prevents vanishing gradient |
| Sigmoid    | $ \frac{1}{1 + e^{-x}} $ | Outputs in [0,1], good for probability |
| Tanh       | $ \tanh(x) $| Outputs in [-1,1], zero-centered |

---

## üîÑ Learning Process (Step by Step)

The learning process in an MLP involves adjusting the weights and biases to reduce the discrepancy between predicted and actual outputs. This is done in four key phases:

### 1Ô∏è‚É£ Forward Propagation
This is the phase where the input $( \mathbf{x} )$ is passed through the network layer by layer to generate a prediction.

Each neuron computes:

$ z^{(l)} = \mathbf{w}^{(l)T} \mathbf{a}^{(l-1)} + b^{(l)}$

$a^{(l)} = \phi(z^{(l)})$

Where:
- $( l )$ is the layer index
- $( \mathbf{a}^{(l-1)} )$ are the activations from the previous layer (or input $( \mathbf{x} )$)
- $( \phi )$ is the non-linear activation function

This continues through all hidden layers and ends in the output layer, producing $( \hat{y} )$.

### 2Ô∏è‚É£ Loss Calculation
Once we obtain the model‚Äôs output $( \hat{y} )$, we compare it with the true label $( y )$ using a **loss function**. Examples:
- Mean Squared Error (for regression):

 $L = \frac{1}{2} (y - \hat{y})^2$

- Cross-Entropy (for classification):

 $L = -[y \log(\hat{y}) + (1 - y) \log(1 - \hat{y})]$

This loss quantifies how far off the predictions are.

### 3Ô∏è‚É£ Backpropagation
To minimize the loss, we compute the gradients of the loss with respect to each weight in the network. This is done using the **chain rule** of calculus.

For each layer $( l )$, we compute:

 $\delta^{(l)} = \frac{\partial L}{\partial z^{(l)}} = \frac{\partial L}{\partial a^{(l)}} \cdot \phi'(z^{(l)})$

Where:
- $( \delta^{(l)} )$ is the **error signal** for layer $( l )$
- $( \phi'(z) )$ is the derivative of the activation function

We then propagate this error backward and compute the gradient of the loss with respect to each weight:

 $\frac{\partial L}{\partial w^{(l)}} = \delta^{(l)} \cdot a^{(l-1)}$

 $\frac{\partial L}{\partial b^{(l)}} = \delta^{(l)}$

This process continues backward from the output layer to the first hidden layer.

### 4Ô∏è‚É£ Weight Update
Once the gradients are computed, we update the weights and biases using an optimization algorithm. The most basic one is **Stochastic Gradient Descent (SGD)**:

 $w^{(l)} \leftarrow w^{(l)} - \eta \frac{\partial L}{\partial w^{(l)}}$

 $b^{(l)} \leftarrow b^{(l)} - \eta \frac{\partial L}{\partial b^{(l)}}$

Where:
- $( \eta )$ is the learning rate
- $( \frac{\partial L}{\partial w^{(l)}} )$ is the gradient of the loss with respect to the weight

This step brings the model‚Äôs predictions closer to the true labels in the next iteration.

üîÅ This process (forward ‚Üí loss ‚Üí backward ‚Üí update) is repeated over multiple **epochs** until the model converges or reaches the desired performance.

---

## üìä MLP vs. Perceptron
| Feature | Perceptron | MLP |
|--------|------------|-----|
| Layers | 1 | 2+ |
| Activation | Step | Non-linear (ReLU, sigmoid, etc.) |
| Decision Boundary | Linear | Non-linear |
| Can Solve XOR? | ‚ùå | ‚úÖ |

---

## ‚úÖ Advantages
- Can model complex non-linear relationships
- Flexible architecture
- Powerful for structured data (tabular), image, and text inputs

## ‚ö†Ô∏è Disadvantages
- Requires careful tuning of architecture and hyperparameters
- Prone to overfitting on small datasets
- More computationally expensive than simple models

---

## üìå Conclusion
MLPs are powerful and flexible neural networks that extend the perceptron by introducing **non-linearity** and **depth**. They form the basis of deep learning and are effective in a wide variety of tasks.

üëâ **Next Steps:** Try implementing an MLP using `scikit-learn` or build one from scratch with `PyTorch` or `TensorFlow`. [here](/notebooks/01_Supervised_Learning/05_Neural_Networks/02_ML.ipynb)!